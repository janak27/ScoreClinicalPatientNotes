{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janak27/ScoreClinicalPatientNotes/blob/main/Score_Clinical_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93db3619"
      },
      "source": [
        "<img src=\"https://janak27.github.io/video/Scoring%20Clinical%20Patients%20Notes.gif\" alt=\"Computer man\"  style=\"width:52px;height:48px;\" >"
      ],
      "id": "93db3619"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e537a3f"
      },
      "source": [
        "# Initialization"
      ],
      "id": "2e537a3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb4a8f7"
      },
      "source": [
        "### Imports"
      ],
      "id": "1fb4a8f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu2sUMfaUXwu"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n"
      ],
      "id": "Xu2sUMfaUXwu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "mBmEezpnUZPD",
        "outputId": "83f2a869-7a00-42a9-f719-34f41c792718"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b00c6e4f-9243-4773-b7da-5219e0563bab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b00c6e4f-9243-4773-b7da-5219e0563bab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"janakbabanavhad\",\"key\":\"fc4eca6bd9181b137e2656d938a95739\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "id": "mBmEezpnUZPD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBTB2vtkUlqr",
        "outputId": "81152c5f-bb7d-4b0c-8ca9-456c3eb2635a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle "
      ],
      "id": "cBTB2vtkUlqr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPcqWxAwUoKZ"
      },
      "outputs": [],
      "source": [
        "# copying json to folder\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "id": "YPcqWxAwUoKZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WdcNhXwUqO7"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "3WdcNhXwUqO7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7peZZLCUshk",
        "outputId": "966f7438-5aa6-4d8c-bdaa-7850e6295970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading nbme-score-clinical-patient-notes.zip to /content\n",
            " 51% 5.00M/9.83M [00:00<00:00, 45.7MB/s]\n",
            "100% 9.83M/9.83M [00:00<00:00, 50.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download -c nbme-score-clinical-patient-notes"
      ],
      "id": "N7peZZLCUshk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHY3aarsVLpN",
        "outputId": "771b9975-6205-4624-ff69-c02e14dd388e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading nbme-roberta-large.zip to /content\n",
            "100% 1.19G/1.19G [00:12<00:00, 163MB/s]\n",
            "100% 1.19G/1.19G [00:12<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d theoviel/nbme-roberta-large"
      ],
      "id": "aHY3aarsVLpN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSEyiZnMVK24",
        "outputId": "88aebcb7-b0f1-4c4c-e92e-94db278c2b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nbme-score-clinical-patient-notes.zip\n",
            "  inflating: features.csv            \n",
            "  inflating: patient_notes.csv       \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "! unzip nbme-score-clinical-patient-notes.zip"
      ],
      "id": "dSEyiZnMVK24"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCYOIAlaVeGM",
        "outputId": "fc8714e0-2b7d-49c1-878c-13cec43e0de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nbme-roberta-large.zip\n",
            "  inflating: roberta-large/config.pth  \n",
            "  inflating: roberta-large/tokenizers/merges.txt  \n",
            "  inflating: roberta-large/tokenizers/special_tokens_map.json  \n",
            "  inflating: roberta-large/tokenizers/tokenizer.json  \n",
            "  inflating: roberta-large/tokenizers/tokenizer_config.json  \n",
            "  inflating: roberta-large/tokenizers/vocab.json  \n",
            "  inflating: roberta-large_0.pt      \n"
          ]
        }
      ],
      "source": [
        "! unzip nbme-roberta-large.zip"
      ],
      "id": "HCYOIAlaVeGM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr1c_t2gVtx7",
        "outputId": "5a213e69-f9d8-4b39-91b6-3d5e70ab0a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ],
      "id": "vr1c_t2gVtx7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f9f9ecd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import ast\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "id": "8f9f9ecd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bb4693d"
      },
      "source": [
        "### Paths"
      ],
      "id": "5bb4693d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a92a60b"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"./\"\n",
        "OUT_PATH = \"./\"\n",
        "WEIGHTS_FOLDER = \"./\"\n",
        "\n",
        "NUM_WORKERS = 2"
      ],
      "id": "1a92a60b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "070b7e99"
      },
      "source": [
        "# Data"
      ],
      "id": "070b7e99"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ca8369"
      },
      "source": [
        "## Preparation"
      ],
      "id": "07ca8369"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "162c2399"
      },
      "outputs": [],
      "source": [
        "def process_feature_text(text):\n",
        "    text = re.sub('I-year', '1-year', text)\n",
        "    text = re.sub('-OR-', \" or \", text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def clean_spaces(txt):\n",
        "    txt = re.sub('\\n', ' ', txt)\n",
        "    txt = re.sub('\\t', ' ', txt)\n",
        "    txt = re.sub('\\r', ' ', txt)\n",
        "#     txt = re.sub(r'\\s+', ' ', txt)\n",
        "    return txt\n",
        "\n",
        "\n",
        "def load_and_prepare_test(root=\"\"):\n",
        "    patient_notes = pd.read_csv(root + \"patient_notes.csv\")\n",
        "    features = pd.read_csv(root + \"features.csv\")\n",
        "    df = pd.read_csv(root + \"test.csv\")\n",
        "\n",
        "    df = df.merge(features, how=\"left\", on=[\"case_num\", \"feature_num\"])\n",
        "    df = df.merge(patient_notes, how=\"left\", on=['case_num', 'pn_num'])\n",
        "\n",
        "    df['pn_history'] = df['pn_history'].apply(lambda x: x.strip())\n",
        "    df['feature_text'] = df['feature_text'].apply(process_feature_text)\n",
        "\n",
        "    df['feature_text'] = df['feature_text'].apply(clean_spaces)\n",
        "    df['clean_text'] = df['pn_history'].apply(clean_spaces)\n",
        "\n",
        "    df['target'] = \"\"\n",
        "    return df"
      ],
      "id": "162c2399"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1a777af"
      },
      "source": [
        "### Processing"
      ],
      "id": "d1a777af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cecb443"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "\n",
        "def token_pred_to_char_pred(token_pred, offsets):\n",
        "    char_pred = np.zeros((np.max(offsets), token_pred.shape[1]))\n",
        "    for i in range(len(token_pred)):\n",
        "        s, e = int(offsets[i][0]), int(offsets[i][1])  # start, end\n",
        "        char_pred[s:e] = token_pred[i]\n",
        "\n",
        "        if token_pred.shape[1] == 3:  # following characters cannot be tagged as start\n",
        "            s += 1\n",
        "            char_pred[s: e, 1], char_pred[s: e, 2] = (\n",
        "                np.max(char_pred[s: e, 1:], 1),\n",
        "                np.min(char_pred[s: e, 1:], 1),\n",
        "            )\n",
        "\n",
        "    return char_pred\n",
        "\n",
        "\n",
        "def labels_to_sub(labels):\n",
        "    all_spans = []\n",
        "    for label in labels:\n",
        "        indices = np.where(label > 0)[0]\n",
        "        indices_grouped = [\n",
        "            list(g) for _, g in itertools.groupby(\n",
        "                indices, key=lambda n, c=itertools.count(): n - next(c)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        spans = [f\"{min(r)} {max(r) + 1}\" for r in indices_grouped]\n",
        "        all_spans.append(\";\".join(spans))\n",
        "    return all_spans\n",
        "\n",
        "\n",
        "def char_target_to_span(char_target):\n",
        "    spans = []\n",
        "    start, end = 0, 0\n",
        "    for i in range(len(char_target)):\n",
        "        if char_target[i] == 1 and char_target[i - 1] == 0:\n",
        "            if end:\n",
        "                spans.append([start, end])\n",
        "            start = i\n",
        "            end = i + 1\n",
        "        elif char_target[i] == 1:\n",
        "            end = i + 1\n",
        "        else:\n",
        "            if end:\n",
        "                spans.append([start, end])\n",
        "            start, end = 0, 0\n",
        "    return spans"
      ],
      "id": "5cecb443"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "040ce2b3"
      },
      "outputs": [],
      "source": [],
      "id": "040ce2b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a546f4e8"
      },
      "source": [
        "## Tokenization"
      ],
      "id": "a546f4e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f82a81a8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "def get_tokenizer(name, precompute=False, df=None, folder=None):\n",
        "    if folder is None:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(folder)\n",
        "\n",
        "    tokenizer.name = name\n",
        "    tokenizer.special_tokens = {\n",
        "        \"sep\": tokenizer.sep_token_id,\n",
        "        \"cls\": tokenizer.cls_token_id,\n",
        "        \"pad\": tokenizer.pad_token_id,\n",
        "    }\n",
        "\n",
        "    if precompute:\n",
        "        tokenizer.precomputed = precompute_tokens(df, tokenizer)\n",
        "    else:\n",
        "        tokenizer.precomputed = None\n",
        "\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def precompute_tokens(df, tokenizer):\n",
        "    feature_texts = df[\"feature_text\"].unique()\n",
        "\n",
        "    ids = {}\n",
        "    offsets = {}\n",
        "\n",
        "    for feature_text in feature_texts:\n",
        "        encoding = tokenizer(\n",
        "            feature_text,\n",
        "            return_token_type_ids=True,\n",
        "            return_offsets_mapping=True,\n",
        "            return_attention_mask=False,\n",
        "            add_special_tokens=False,\n",
        "        )\n",
        "        ids[feature_text] = encoding[\"input_ids\"]\n",
        "        offsets[feature_text] = encoding[\"offset_mapping\"]\n",
        "\n",
        "    texts = df[\"clean_text\"].unique()\n",
        "\n",
        "    for text in texts:\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            return_token_type_ids=True,\n",
        "            return_offsets_mapping=True,\n",
        "            return_attention_mask=False,\n",
        "            add_special_tokens=False,\n",
        "        )\n",
        "        ids[text] = encoding[\"input_ids\"]\n",
        "        offsets[text] = encoding[\"offset_mapping\"]\n",
        "\n",
        "    return {\"ids\": ids, \"offsets\": offsets}\n",
        "\n",
        "\n",
        "def encodings_from_precomputed(feature_text, text, precomputed, tokenizer, max_len=300):\n",
        "    tokens = tokenizer.special_tokens\n",
        "\n",
        "    # Input ids\n",
        "    if \"roberta\" in tokenizer.name:\n",
        "        qa_sep = [tokens[\"sep\"], tokens[\"sep\"]]\n",
        "    else:\n",
        "        qa_sep = [tokens[\"sep\"]]\n",
        "\n",
        "    input_ids = [tokens[\"cls\"]] + precomputed[\"ids\"][feature_text] + qa_sep\n",
        "    n_question_tokens = len(input_ids)\n",
        "\n",
        "    input_ids += precomputed[\"ids\"][text]\n",
        "    input_ids = input_ids[: max_len - 1] + [tokens[\"sep\"]]\n",
        "\n",
        "    # Token type ids\n",
        "    if \"roberta\" not in tokenizer.name:\n",
        "        token_type_ids = np.ones(len(input_ids))\n",
        "        token_type_ids[:n_question_tokens] = 0\n",
        "        token_type_ids = token_type_ids.tolist()\n",
        "    else:\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "    # Offsets\n",
        "    offsets = [(0, 0)] * n_question_tokens + precomputed[\"offsets\"][text]\n",
        "    offsets = offsets[: max_len - 1] + [(0, 0)]\n",
        "\n",
        "    # Padding\n",
        "    padding_length = max_len - len(input_ids)\n",
        "    if padding_length > 0:\n",
        "        input_ids = input_ids + ([tokens[\"pad\"]] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        offsets = offsets + ([(0, 0)] * padding_length)\n",
        "\n",
        "    encoding = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"token_type_ids\": token_type_ids,\n",
        "        \"offset_mapping\": offsets,\n",
        "    }\n",
        "\n",
        "    return encoding\n"
      ],
      "id": "f82a81a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "135a3e82"
      },
      "source": [
        "## Dataset"
      ],
      "id": "135a3e82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6510627b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class PatientNoteDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.df = df\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.texts = df['clean_text'].values\n",
        "        self.feature_text = df['feature_text'].values\n",
        "        self.char_targets = df['target'].values.tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        feature_text = self.feature_text[idx]\n",
        "        char_target = self.char_targets[idx]\n",
        "\n",
        "        # Tokenize\n",
        "        if self.tokenizer.precomputed is None:\n",
        "            encoding = self.tokenizer(\n",
        "                feature_text,\n",
        "                text,\n",
        "                return_token_type_ids=True,\n",
        "                return_offsets_mapping=True,\n",
        "                return_attention_mask=False,\n",
        "                truncation=\"only_second\",\n",
        "                max_length=self.max_len,\n",
        "                padding='max_length',\n",
        "            )\n",
        "            raise NotImplementedError(\"fix issues with question offsets\")\n",
        "        else:\n",
        "            encoding = encodings_from_precomputed(\n",
        "                feature_text,\n",
        "                text,\n",
        "                self.tokenizer.precomputed,\n",
        "                self.tokenizer,\n",
        "                max_len=self.max_len\n",
        "            )\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(encoding[\"input_ids\"], dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(encoding[\"token_type_ids\"], dtype=torch.long),\n",
        "            \"target\": torch.tensor([0], dtype=torch.float),\n",
        "            \"offsets\": np.array(encoding[\"offset_mapping\"]),\n",
        "            \"text\": text,\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n"
      ],
      "id": "6510627b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57da52b4"
      },
      "source": [
        "### Plot predictions"
      ],
      "id": "57da52b4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b4621a4"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "def plot_annotation(df, pn_num):\n",
        "    options = {\"colors\": {}}\n",
        "\n",
        "    df_text = df[df[\"pn_num\"] == pn_num].reset_index(drop=True)\n",
        "\n",
        "    text = df_text[\"pn_history\"][0]\n",
        "    ents = []\n",
        "\n",
        "    for spans, feature_text, feature_num in df_text[[\"span\", \"feature_text\", \"feature_num\"]].values:\n",
        "        for s in spans:\n",
        "            ents.append({\"start\": int(s[0]), \"end\": int(s[1]), \"label\": feature_text})\n",
        "\n",
        "        options[\"colors\"][feature_text] =  f\"rgb{tuple(np.random.randint(100, 255, size=3))}\"\n",
        "\n",
        "    doc = {\"text\": text, \"ents\": sorted(ents, key=lambda i: i[\"start\"])}\n",
        "   \n",
        "    spacy.displacy.render(doc, style=\"ent\", options=options, manual=True, jupyter=True)"
      ],
      "id": "5b4621a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0dae799"
      },
      "source": [
        "# Model"
      ],
      "id": "f0dae799"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f96dc704"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "\n",
        "class NERTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        num_classes=1,\n",
        "        config_file=None,\n",
        "        pretrained=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.name = model\n",
        "        self.pad_idx = 1 if \"roberta\" in self.name else 0\n",
        "\n",
        "        transformers.logging.set_verbosity_error()\n",
        "\n",
        "        if config_file is None:\n",
        "            config = AutoConfig.from_pretrained(model, output_hidden_states=True)\n",
        "        else:\n",
        "            config = torch.load(config_file)\n",
        "\n",
        "        if pretrained:\n",
        "            self.transformer = AutoModel.from_pretrained(model, config=config)\n",
        "        else:\n",
        "            self.transformer = AutoModel.from_config(config)\n",
        "\n",
        "        self.nb_features = config.hidden_size\n",
        "\n",
        "#         self.cnn = nn.Identity()\n",
        "        self.logits = nn.Linear(self.nb_features, num_classes)\n",
        "\n",
        "    def forward(self, tokens, token_type_ids):\n",
        "        \"\"\"\n",
        "        Usual torch forward function\n",
        "\n",
        "        Arguments:\n",
        "            tokens {torch tensor} -- Sentence tokens\n",
        "            token_type_ids {torch tensor} -- Sentence tokens ids\n",
        "        \"\"\"\n",
        "        hidden_states = self.transformer(\n",
        "            tokens,\n",
        "            attention_mask=(tokens != self.pad_idx).long(),\n",
        "            token_type_ids=token_type_ids,\n",
        "        )[-1]\n",
        "\n",
        "        features = hidden_states[-1]\n",
        "\n",
        "        logits = self.logits(features)\n",
        "\n",
        "        return logits"
      ],
      "id": "f96dc704"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8752fc"
      },
      "source": [
        "## Loads weights"
      ],
      "id": "1e8752fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d789cc3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def load_model_weights(model, filename, verbose=1, cp_folder=\"\", strict=True):\n",
        "    \"\"\"\n",
        "    Loads the weights of a PyTorch model. The exception handles cpu/gpu incompatibilities.\n",
        "\n",
        "    Args:\n",
        "        model (torch model): Model to load the weights to.\n",
        "        filename (str): Name of the checkpoint.\n",
        "        verbose (int, optional): Whether to display infos. Defaults to 1.\n",
        "        cp_folder (str, optional): Folder to load from. Defaults to \"\".\n",
        "        strict (bool, optional): Whether to allow missing/additional keys. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        torch model: Model with loaded weights.\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"\\n -> Loading weights from {os.path.join(cp_folder,filename)}\\n\")\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\"),\n",
        "            strict=strict,\n",
        "        )\n",
        "    except RuntimeError:\n",
        "        model.encoder.fc = torch.nn.Linear(model.nb_ft, 1)\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\"),\n",
        "            strict=strict,\n",
        "        )\n",
        "\n",
        "    return model"
      ],
      "id": "8d789cc3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2744630d"
      },
      "source": [
        "## Predict"
      ],
      "id": "2744630d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a9903a7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def predict(model, dataset, data_config, activation=\"softmax\"):\n",
        "    \"\"\"\n",
        "    Usual predict torch function\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=data_config['val_bs'],\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(loader):\n",
        "            ids, token_type_ids = data[\"ids\"], data[\"token_type_ids\"]\n",
        "\n",
        "      \n",
        "            print(\"nn process started\")\n",
        "            # y_pred = model(ids.cuda(), token_type_ids.cuda())\n",
        "            y_pred = model(ids.cpu(), token_type_ids.cpu())\n",
        "            if activation == \"sigmoid\":\n",
        "                y_pred = y_pred.sigmoid()\n",
        "            elif activation == \"softmax\":\n",
        "                y_pred = y_pred.softmax(-1)\n",
        "                \n",
        "            print(\"nn process complted\")\n",
        "\n",
        "            preds += [\n",
        "                token_pred_to_char_pred(y, offsets) for y, offsets\n",
        "                in zip(y_pred.detach().cpu().numpy(), data[\"offsets\"].numpy())\n",
        "            ]\n",
        "            break\n",
        "\n",
        "    return preds\n"
      ],
      "id": "7a9903a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d315746d"
      },
      "source": [
        "## Inference"
      ],
      "id": "d315746d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "712899aa"
      },
      "outputs": [],
      "source": [
        "def inference_test(df, exp_folder, config, cfg_folder=None):\n",
        "    preds = []\n",
        "\n",
        "    if cfg_folder is not None:\n",
        "        model_config_file = cfg_folder + config.name.split('/')[-1] + \"/config.pth\"\n",
        "        tokenizer_folder = cfg_folder + config.name.split('/')[-1] + \"/tokenizers/\"\n",
        "    else:\n",
        "        model_config_file, tokenizer_folder = None, None\n",
        "\n",
        "    tokenizer = get_tokenizer(\n",
        "        config.name, precompute=config.precompute_tokens, df=df, folder=tokenizer_folder\n",
        "    )\n",
        "\n",
        "    dataset = PatientNoteDataset(\n",
        "        df,\n",
        "        tokenizer,\n",
        "        max_len=config.max_len,\n",
        "    )\n",
        "\n",
        "    model = NERTransformer(\n",
        "        config.name,\n",
        "        num_classes=config.num_classes,\n",
        "        config_file=model_config_file,\n",
        "        pretrained=False\n",
        "    ).cpu()\n",
        "    model.zero_grad()\n",
        "\n",
        "    weights = sorted(glob.glob(exp_folder + \"*.pt\"))\n",
        "    for weight in weights:\n",
        "        model = load_model_weights(model, weight)\n",
        "\n",
        "        pred = predict(\n",
        "            model,\n",
        "            dataset,\n",
        "            data_config=config.data_config,\n",
        "            activation=config.loss_config[\"activation\"]\n",
        "        )\n",
        "        preds.append(pred)\n",
        "\n",
        "    return preds"
      ],
      "id": "712899aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d7dd47e"
      },
      "source": [
        "## Config"
      ],
      "id": "2d7dd47e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf2ac129"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    # Architecture\n",
        "    name = \"roberta-large\"\n",
        "    num_classes = 1\n",
        "\n",
        "    # Texts\n",
        "    max_len = 310\n",
        "    precompute_tokens = True\n",
        "\n",
        "    # Training    \n",
        "    loss_config = {\n",
        "        \"activation\": \"sigmoid\",\n",
        "    }\n",
        "\n",
        "    data_config = {\n",
        "        \"val_bs\": 16 if \"large\" in name else 32,\n",
        "        \"pad_token\": 1 if \"roberta\" in name else 0,\n",
        "    }\n",
        "\n",
        "    verbose = 1"
      ],
      "id": "cf2ac129"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7b48d08"
      },
      "source": [
        "## Inference"
      ],
      "id": "c7b48d08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZLqKMCtVmHU"
      },
      "outputs": [],
      "source": [
        "def post_process_spaces(target, text):\n",
        "    target = np.copy(target)\n",
        "\n",
        "    if len(text) > len(target):\n",
        "        padding = np.zeros(len(text) - len(target))\n",
        "        target = np.concatenate([target, padding])\n",
        "    else:\n",
        "        target = target[:len(text)]\n",
        "\n",
        "    if text[0] == \" \":\n",
        "        target[0] = 0\n",
        "    if text[-1] == \" \":\n",
        "        target[-1] = 0\n",
        "\n",
        "    for i in range(1, len(text) - 1):\n",
        "        if text[i] == \" \":\n",
        "            if target[i] and not target[i - 1]:  # space before\n",
        "                target[i] = 0\n",
        "\n",
        "            if target[i] and not target[i + 1]:  # space after\n",
        "                target[i] = 0\n",
        "\n",
        "            if target[i - 1] and target[i + 1]:\n",
        "                target[i] = 1\n",
        "\n",
        "    return target"
      ],
      "id": "_ZLqKMCtVmHU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sIs2W2nlwO-M",
        "outputId": "62b90a6f-9e29-4b6f-9757-5ddb32e225c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  case_num  pn_num  feature_num  \\\n",
              "0  00016_000         0      16            0   \n",
              "1  00016_001         0      16            1   \n",
              "2  00016_002         0      16            2   \n",
              "3  00016_003         0      16            3   \n",
              "4  00016_004         0      16            4   \n",
              "\n",
              "                                        feature_text  \\\n",
              "0  Family history of MI or Family history of myoc...   \n",
              "1                 Family history of thyroid disorder   \n",
              "2                                     Chest pressure   \n",
              "3                              Intermittent symptoms   \n",
              "4                                        Lightheaded   \n",
              "\n",
              "                                          pn_history  \\\n",
              "0  HPI: 17yo M presents with palpitations. Patien...   \n",
              "1  HPI: 17yo M presents with palpitations. Patien...   \n",
              "2  HPI: 17yo M presents with palpitations. Patien...   \n",
              "3  HPI: 17yo M presents with palpitations. Patien...   \n",
              "4  HPI: 17yo M presents with palpitations. Patien...   \n",
              "\n",
              "                                          clean_text target  \n",
              "0  HPI: 17yo M presents with palpitations. Patien...         \n",
              "1  HPI: 17yo M presents with palpitations. Patien...         \n",
              "2  HPI: 17yo M presents with palpitations. Patien...         \n",
              "3  HPI: 17yo M presents with palpitations. Patien...         \n",
              "4  HPI: 17yo M presents with palpitations. Patien...         "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c509332-1420-4539-9c3d-ca9d1a1551ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>case_num</th>\n",
              "      <th>pn_num</th>\n",
              "      <th>feature_num</th>\n",
              "      <th>feature_text</th>\n",
              "      <th>pn_history</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00016_000</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>Family history of MI or Family history of myoc...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00016_001</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>Family history of thyroid disorder</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00016_002</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>Chest pressure</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00016_003</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>Intermittent symptoms</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00016_004</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>Lightheaded</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c509332-1420-4539-9c3d-ca9d1a1551ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c509332-1420-4539-9c3d-ca9d1a1551ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c509332-1420-4539-9c3d-ca9d1a1551ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df_test = load_and_prepare_test(root=DATA_PATH)\n",
        "df_test.head()\n",
        "# df_test.drop([\"id\"],inplace=True,axis=1)\n",
        "# df_test.drop(df_test.index, inplace=True)"
      ],
      "id": "sIs2W2nlwO-M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "827fae93"
      },
      "source": [
        "## Result"
      ],
      "id": "827fae93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUEVjMAu0aw0"
      },
      "outputs": [],
      "source": [
        "data={\n",
        "\"feature_text\":\"\",\n",
        "\"pn_history\":\"\",\n",
        "\"clean_text\":\"\"\n",
        "}"
      ],
      "id": "CUEVjMAu0aw0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "NmciR6ES0c8a"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "import ipywidgets as widgets\n",
        "# data={\n",
        "# \"feature_text\":\"\",\n",
        "# \"pn_history\":\"\",\n",
        "# \"clean_text\":\"\"\n",
        "# }\n",
        "def remove_all_rows():\n",
        "    df_test.drop(df_test.index, inplace=True)\n",
        "\n",
        "feature_textW=widgets.Text(\n",
        "    value=data[\"feature_text\"],\n",
        "    placeholder='feature_text',\n",
        "    description='feature_text:',\n",
        "    continuous_update=True\n",
        "   \n",
        ")\n",
        "pn_historyW=widgets.Textarea(\n",
        "    value=data[\"pn_history\"],\n",
        "    placeholder='pn_history',\n",
        "    description='pn_history:',\n",
        "    continuous_update=True\n",
        "   \n",
        ")\n",
        "\n",
        "clean_textW=widgets.Textarea(\n",
        "    value=data[\"clean_text\"],\n",
        "    placeholder='clean_text',\n",
        "    description='clean_text:',\n",
        "    continuous_update=True\n",
        "   \n",
        ")\n",
        "def value_changedfeature_textW(change):\n",
        "  # print(change.new)\n",
        "  data[\"feature_text\"]=change.new\n",
        "feature_textW.observe(value_changedfeature_textW, 'value')\n",
        "\n",
        "def value_changedpn_historyW(change):\n",
        "  # print(change.new)\n",
        "  data[\"pn_history\"]=change.new\n",
        "pn_historyW.observe(value_changedpn_historyW, 'value')\n",
        "\n",
        "def value_changedclean_textW(change):\n",
        "  # print(change.new)\n",
        "  data[\"clean_text\"]=change.new\n",
        "clean_textW.observe(value_changedclean_textW, 'value')\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='Predict',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Predict',\n",
        "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "\n",
        "def run_predict(aa):\n",
        "    print(\"predection Started\")\n",
        "    \n",
        "    df_test = load_and_prepare_test(root=DATA_PATH)\n",
        "    df_test.head()\n",
        "    df_test.drop([\"id\"],inplace=True,axis=1)\n",
        "    df_test.drop(df_test.index, inplace=True)\n",
        "\n",
        " \n",
        "    df_test.loc[len(df_test.index)] = [0,16,5,data[\"feature_text\"],data[\"pn_history\"],data[\"clean_text\"],\"\"] \n",
        "   \n",
        "    preds = inference_test(\n",
        "    df_test,\n",
        "    WEIGHTS_FOLDER,\n",
        "    Config,\n",
        "    cfg_folder=OUT_PATH\n",
        "    )[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    df_test['preds'] = preds\n",
        "    df_test['preds'] = df_test.apply(lambda x: x['preds'][:len(x['clean_text'])], 1)\n",
        "    df_test['preds'] = df_test['preds'].apply(lambda x: (x > 0.5).flatten())\n",
        "    try:\n",
        "        df_test['span'] = df_test['preds'].apply(char_target_to_span)\n",
        "        plot_annotation(df_test, df_test['pn_num'][0])\n",
        "    except:\n",
        "        pass\n",
        "    df_test['preds_pp'] = df_test.apply(lambda x: post_process_spaces(x['preds'], x['clean_text']), 1)\n",
        "    # try:\n",
        "    #     df_test['span'] = df_test['preds_pp'].apply(char_target_to_span)\n",
        "    #     plot_annotation(df_test, df_test['pn_num'][0])\n",
        "    # except:\n",
        "    #     pass\n",
        "\n",
        "\n",
        "        \n",
        "    df_test['location'] = labels_to_sub(df_test['preds_pp'].values)\n",
        "    print(\"score:\",df_test['location'][0])\n",
        "    a=df_test['location'][0].split()\n",
        "    \n",
        "    \n",
        "    try:\n",
        "        print(f\"accuracy score {round((int(a[0])/int(a[1]))*100,2)}%\")\n",
        "    except Exception as e:\n",
        "        print(\"\")\n",
        "        \n",
        "\n",
        "button.on_click(run_predict)\n"
      ],
      "id": "NmciR6ES0c8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sq1Q1u9ei8q"
      },
      "source": [
        "\n",
        "<img src=\"https://janak27.github.io/video/Pink%20Colorful%20Gradient%20Motivational%20Quote%20Twitter%20Header.gif\" alt=\"Computer man\"  style=\"width:48px;height:48px;\" >"
      ],
      "id": "3Sq1Q1u9ei8q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "2f28743da9284b319cd1a47c0e6e8a83",
            "4312fb33f22642339d88a4a9d762cbf3",
            "3f901a4cc12440479862d96669a4a795",
            "d631178f4caf4a38b093fae5874c2a7e",
            "6b294412672b4485b12e2c91a7cf9ca0",
            "eba72f28adcd491484fc3a8103159e93",
            "6a6ab7aa904044fc9314bc1e5a4e8608",
            "f64b7f8a845b4200a9ee94237cf0a123",
            "bda8ea497b1e4b3dba71586c0da8362e",
            "cd671e9f59e5497b8b98c24910cdbb9b",
            "437c26ceef7048b1a4f6595df7dcce19",
            "62740fe1542641db91be526d038fdb3a"
          ]
        },
        "id": "4mYI_KYq-MVA",
        "outputId": "5de378bc-0f02-4f91-f98a-3873018bba16"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='feature_text:', placeholder='feature_text')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f28743da9284b319cd1a47c0e6e8a83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='pn_history:', placeholder='pn_history')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d631178f4caf4a38b093fae5874c2a7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='clean_text:', placeholder='clean_text')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a6ab7aa904044fc9314bc1e5a4e8608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Predict', icon='check', style=ButtonStyle(), tooltip='Predict')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd671e9f59e5497b8b98c24910cdbb9b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(feature_textW,pn_historyW,clean_textW,button)"
      ],
      "id": "4mYI_KYq-MVA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvUdlwCXD_Y1"
      },
      "outputs": [],
      "source": [],
      "id": "wvUdlwCXD_Y1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wWLe0vpSJEe"
      },
      "source": [
        "**TEST DATA 1** <br><br>\n",
        "Family history of MI or Family history of myocardial infarction\n",
        "</br><br>\n",
        "HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \n",
        "PMHx: none\n",
        "Rx: uses friends adderrall\n",
        "FHx: mom with \"thyroid disease,\" dad with recent heart attcak\n",
        "All: none\n",
        "Immunizations: up to date\n",
        "SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms\n",
        "<br><br>\n",
        "HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits.   PMHx: none  Rx: uses friends adderrall  FHx: mom with \"thyroid disease,\" dad with recent heart attcak  All: none  Immunizations: up to date  SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms"
      ],
      "id": "1wWLe0vpSJEe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZAI992R8U5A"
      },
      "source": [
        "**TEST DATA 2** <br><br>\n",
        "Family history of thyroid disorder\n",
        "<br><br>\n",
        "HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \n",
        "PMHx: none\n",
        "Rx: uses friends adderrall\n",
        "FHx: mom with \"thyroid disease,\" dad with recent heart attcak\n",
        "All: none\n",
        "Immunizations: up to date\n",
        "SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms\n",
        "<br><br>\n",
        "HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits.   PMHx: none  Rx: uses friends adderrall  FHx: mom with \"thyroid disease,\" dad with recent heart attcak  All: none  Immunizations: up to date  SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms"
      ],
      "id": "NZAI992R8U5A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFWoQpmF8win"
      },
      "source": [
        "**TEST DATA 3**<br><br>\n",
        "Chest pressure\n",
        "<br><br>\n",
        "HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \n",
        "PMHx: none\n",
        "Rx: uses friends adderrall\n",
        "FHx: mom with \"thyroid disease,\" dad with recent heart attcak\n",
        "All: none\n",
        "Immunizations: up to date\n",
        "SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms\n",
        "<br><br>\n",
        "HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits.   PMHx: none  Rx: uses friends adderrall  FHx: mom with \"thyroid disease,\" dad with recent heart attcak  All: none  Immunizations: up to date  SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms"
      ],
      "id": "rFWoQpmF8win"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 53.437563,
      "end_time": "2022-03-03T15:41:23.397223",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-03-03T15:40:29.959660",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f28743da9284b319cd1a47c0e6e8a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "feature_text:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4312fb33f22642339d88a4a9d762cbf3",
            "placeholder": "feature_text",
            "style": "IPY_MODEL_3f901a4cc12440479862d96669a4a795",
            "value": ""
          }
        },
        "4312fb33f22642339d88a4a9d762cbf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f901a4cc12440479862d96669a4a795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d631178f4caf4a38b093fae5874c2a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "pn_history:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6b294412672b4485b12e2c91a7cf9ca0",
            "placeholder": "pn_history",
            "rows": null,
            "style": "IPY_MODEL_eba72f28adcd491484fc3a8103159e93",
            "value": ""
          }
        },
        "6b294412672b4485b12e2c91a7cf9ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba72f28adcd491484fc3a8103159e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a6ab7aa904044fc9314bc1e5a4e8608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "clean_text:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f64b7f8a845b4200a9ee94237cf0a123",
            "placeholder": "clean_text",
            "rows": null,
            "style": "IPY_MODEL_bda8ea497b1e4b3dba71586c0da8362e",
            "value": ""
          }
        },
        "f64b7f8a845b4200a9ee94237cf0a123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda8ea497b1e4b3dba71586c0da8362e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd671e9f59e5497b8b98c24910cdbb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Predict",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_437c26ceef7048b1a4f6595df7dcce19",
            "style": "IPY_MODEL_62740fe1542641db91be526d038fdb3a",
            "tooltip": "Predict"
          }
        },
        "437c26ceef7048b1a4f6595df7dcce19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62740fe1542641db91be526d038fdb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}